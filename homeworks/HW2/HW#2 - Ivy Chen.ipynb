{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2  | Correlation, Casuation, & Regression\n",
    "### Assigned Tuesday, 6 Mar 2018  /  Due Tuesday, Mar 13 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal:\n",
    "We're going to spend some time thinking through claims of causation and correlation. We already saw in our Freedman and Desrosieres readings, and in our discussion of lab 6 (\"Yuletide\"), that Yule's 1899 \"An Investigation into the Causes of changes in Pauperism[...]\" argued that pauperism was *caused* by giving monetary aid to the poor (i.e., 'out-relief'). Earlier, in 1897, Yule had suggesting linear regression using the method of least squares (i.e., generating a line formed by minimizing the square of the redsiduals) and to use multiple variable regressions (Desrosieres 134). You're going to get more familar with some of the statistical techniques that Yule and others were using, reflect upon the assumptions of these tools, and, as always, reflect upon the provenance of the data we're using.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Problems \n",
    "#### This assignment is to be done on your own. Provide your code to justify your answer to each question.  Be sure to rename this homework so that it includes your name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 1) \n",
    "We're going to use the data that we used for lab 6 - Yuletide. One line of code has been provided. Download this data and use head command to re-familarize yourself with the data. Then use describe to get a sense of how the data is distributed. (Note that \"MRI_count\" here is a measure of brain size. Also recall the long history of using brain size to argue for different racial differences in intelligence, as discussed by Gould's *The Mismeasure of Man* and others.) [2 points] \n",
    "\n",
    "Ten points of EXTRA CREDIT if you can track down some useful (i.e., citable) information about where this data set came from, where it was used, or how it was produced.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://www.scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FSIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>PIQ</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>MRI_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>124</td>\n",
       "      <td>118.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>816932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>140</td>\n",
       "      <td>150</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>139</td>\n",
       "      <td>123</td>\n",
       "      <td>150</td>\n",
       "      <td>143.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1038437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>172.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>965353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>137</td>\n",
       "      <td>132</td>\n",
       "      <td>134</td>\n",
       "      <td>147.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>951545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Gender  FSIQ  VIQ  PIQ  Weight  Height  MRI_Count\n",
       "0           1  Female   133  132  124   118.0    64.5     816932\n",
       "1           2    Male   140  150  124     NaN    72.5    1001121\n",
       "2           3    Male   139  123  150   143.0    73.3    1038437\n",
       "3           4    Male   133  129  128   172.0    68.8     965353\n",
       "4           5  Female   137  132  134   147.0    65.0     951545"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FSIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>PIQ</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>MRI_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>113.450000</td>\n",
       "      <td>112.350000</td>\n",
       "      <td>111.02500</td>\n",
       "      <td>151.052632</td>\n",
       "      <td>68.525641</td>\n",
       "      <td>9.087550e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.690452</td>\n",
       "      <td>24.082071</td>\n",
       "      <td>23.616107</td>\n",
       "      <td>22.47105</td>\n",
       "      <td>23.478509</td>\n",
       "      <td>3.994649</td>\n",
       "      <td>7.228205e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>72.00000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>7.906190e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.750000</td>\n",
       "      <td>89.750000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>88.25000</td>\n",
       "      <td>135.250000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>8.559185e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>115.00000</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9.053990e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>135.500000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>128.00000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>9.500780e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.079549e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        FSIQ         VIQ        PIQ      Weight     Height  \\\n",
       "count   40.000000   40.000000   40.000000   40.00000   38.000000  39.000000   \n",
       "mean    20.500000  113.450000  112.350000  111.02500  151.052632  68.525641   \n",
       "std     11.690452   24.082071   23.616107   22.47105   23.478509   3.994649   \n",
       "min      1.000000   77.000000   71.000000   72.00000  106.000000  62.000000   \n",
       "25%     10.750000   89.750000   90.000000   88.25000  135.250000  66.000000   \n",
       "50%     20.500000  116.500000  113.000000  115.00000  146.500000  68.000000   \n",
       "75%     30.250000  135.500000  129.750000  128.00000  172.000000  70.500000   \n",
       "max     40.000000  144.000000  150.000000  150.00000  192.000000  77.000000   \n",
       "\n",
       "          MRI_Count  \n",
       "count  4.000000e+01  \n",
       "mean   9.087550e+05  \n",
       "std    7.228205e+04  \n",
       "min    7.906190e+05  \n",
       "25%    8.559185e+05  \n",
       "50%    9.053990e+05  \n",
       "75%    9.500780e+05  \n",
       "max    1.079549e+06  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the usual libraries, you'll also need the stats library for this homework. Let's just add it now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 2) \n",
    "\n",
    "What is the Pearson correlation coefficient $r$ and what does it tell you about correlation? Explain the possible values for $r$ and what that tells you about correlation. Now compute r for FSIQ vs VIQ, Weight vs Height, and MRI_count vs PIQ using `st.pearsonr` (see lab 6). Explain the correlation between these three pairs of variables using $r$. [10 points, 100 words max]  \n",
    "\n",
    "EXTRA CREDIT: Above I've asked you to provide a mathematical interpretation of $r$, but (as I hope is very clear from our class discussions and from the readings) the very decision to correlate intelligence to brain size is deeply problematic. Why? If $r$ suggests there is a correlation between two things we already understand to be uncorrelated, where did we go wrong? [5 extra credit points, 50 words max]    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Response:\n",
    "\n",
    "The Pearson correlation coefficient $r$ gives two pieces of information (direction and strength) and it tells us whether there is a strong positive/negative or no correlation between two variables. The two extremums are +1 and -1, and 0 indicates that there is no correlation.\n",
    "\n",
    "We found the following correlation coefficients:\n",
    "* FSIQ vs. VIQ: r=.94511 -- indicates highly positive correlation between the two measures of intelligence\n",
    "* Weight vs. Height: r=.69961 -- indicates positive correlation between weight and height (we know this to be generally true, that taller people weigh more than shorter people)\n",
    "* MRI_Count vs. PIQ: r=.377781 -- indicates a slightly positive correlation between brain size and PIQ measure of intelligence\n",
    "\n",
    "EC: If $r$ suggets a correlation between two things we already know to be uncorrelated, and we still continue to look for a connection between the two, we are making the mistake of using correlation to imply causation. In the case of craniometry, scientists attempted to use the correlation between the two to explain how larger brains impacted intelligence (and also correlate that with brain sizes of different demographic groups).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9451142929017027, 4.520765026525871e-19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing pearsons correlation coefficients\n",
    "st.pearsonr(data.dropna()['FSIQ'], data.dropna()['VIQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.699614004238759, 1.0214620551543478e-06)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing pearsons correlation coefficients\n",
    "st.pearsonr(data.dropna()['Weight'], data.dropna()['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37778161934670607, 0.019366055094400248)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing pearsons correlation coefficients\n",
    "st.pearsonr(data.dropna()['MRI_Count'], data.dropna()['PIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 3) \n",
    "\n",
    "Explain the possible values for $R^2$, and what that tells you about correlation. Compute the $R^2$ value for FSIQ vs VIQ, Weight vs Height, and MRI_count vs PIQ. (See \"lab 5 - Yuletide\" for how to compute $R^2$). Is just using $R^2$ sufficient to determine correlation? Explain. [10 points, 100 words max]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response:\n",
    "\n",
    "The possible values for $R^2$ are between 0 and 100% and it indicates how close the data is to the fitted regression line. $R^2$ is the square of the Pearson's correlation coefficient, and measures how differences in one of the variables is explained by differences in the second variable.\n",
    "\n",
    "Values:\n",
    "* FSIQ vs. VIQ: r2=.89324\n",
    "* Weight vs. Height: r2=.489459\n",
    "* MRI_Count vs. PIQ: r2=.142718\n",
    "\n",
    "Using the $R^2$ value is not sufficient as it is a measure of how well the data conforms to our regression equation/how much of the change in Y can be explained by the change in X... A higher $R^2$ indicates a better fit. While it does give a measure of strength of correlation, it doesn't give the direction of correlation (which we can obtain from the Pearson's coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932410266470858"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope, intercept, r_value, p_value, std_err = st.linregress(data.dropna()['FSIQ'], data.dropna()['VIQ'])\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48945975492699023"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope, intercept, r_value, p_value, std_err = st.linregress(data.dropna()['Weight'], data.dropna()['Height'])\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14271895191621953"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope, intercept, r_value, p_value, std_err = st.linregress(data.dropna()['MRI_Count'], data.dropna()['PIQ'])\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 4) \n",
    "Perform two different linear regressions using the scikit-learn library (as demonstrated in \"Lab 5 - Yuletide\"), in which each regression compares two variables from the data above. How strong is the correlation for the two pairs of variables you regressed upon? [10 points] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response:\n",
    "* The correlation between MRI_Count vs. PIQ is not very strong ($R^2$ is only.142718)\n",
    "* The correlation between Weight and MRI_Count is slightly stonger, but still no significant correlation ($R^2$ is .26355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "0.14271895191621942\n",
      "Coefficients: \n",
      "0.26355747653178174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivycn\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "C:\\Users\\ivycn\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:22: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# First Linear Regression\n",
    "\n",
    "data_X = data.dropna()['MRI_Count']\n",
    "data_X = data_X.reshape(-1,1)\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "data_y = data.dropna()['PIQ']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "regr.fit(data_X, data_y)\n",
    "\n",
    "print('Coefficients: ',)\n",
    "print(regr.score(data_X,data_y))\n",
    "\n",
    "# Second Linear Regression\n",
    "data_X = data.dropna()['Weight']\n",
    "data_X = data_X.reshape(-1,1)\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "data_y = data.dropna()['MRI_Count']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "regr.fit(data_X, data_y)\n",
    "\n",
    "print('Coefficients: ')\n",
    "print(regr.score(data_X,data_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 5)\n",
    "\n",
    "Consider your answer in question 4: What assumptions do we have to make if we wish to argue that the linear regression you performed demonstrates a causal relationship? (Hint: Recall Yule's argument about this that we saw in lab 5.) Are these assumptions valid for the data you used in problem 4? Explain. [10 points, 100 words max]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Response: In order to argue that the linear regression demonstrates a causal relationship, we must keep all other factors constant and only vary the factors we want to detemine the correlation for. As per Yule: \"there is still a chance of error depending on the number of factors correlated with ..., but the chance of error will be much smaller than before\". These assumptions are not valid for the data used in Problem 4. If we look at our dataframe, we see that each of the characteristics varies across different samples. We have a fairly small number of samples, and cannot assume that factors we are not finding the linear regression for are held constant between samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 6)\n",
    "Generally, what is the purpose of performing a t-test? What's the difference between st.ttest_1samp() and st.ttest_ind(). Use the ? to get documents. [10 points, 100 words max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "? st.ttest_1samp()\n",
    "? st.ttest_ind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Response: The purpose of a t-test is to analyze population means ie. to determine if the mean of a population differs significantly from a specific value (the hypothesized mean) or from the mean of another population.\n",
    "\n",
    "The st.ttest_1samp() is used to calculate the t-test for the mean of ONE group of scores. From the manual: \"This is a two-sided test for the null hypothesis that the expected value (mean) of a sample of independent observations `a` is equal to the given population mean, `popmean`.\"\n",
    "\n",
    "In contrast, st.ttest_ind() calculates the t-test for the means of two independent samples of scores. From the manual: \"This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 7) \n",
    "What does <code>st.ttest_1samp(data['VIQ'], 100)</code> do and how should it be interpreted? What would Fisher say about this? Likewise, what question does  <code>st.ttest_1samp(data['FSIQ'] - data['PIQ'], 0)</code> ask and how should the result be interpreted? [10 points, 100 words max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=3.3074146385401786, pvalue=0.002030117404781822)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.ttest_1samp(data['VIQ'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=1.7842019405859857, pvalue=0.08217263818364236)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.ttest_1samp(data['FSIQ'] - data['PIQ'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response: st.ttest_1samp(data['VIQ'], 100) performs the 1 sample t-test on the VIQ data comparing the expected mean of the sample to the given population mean of 100. In this case, we note that the statistic is around ~3, indicating that the groups are different by that magnitude. In addition, the low p-value (<.01) indicates that our data did not occur by chance.\n",
    "\n",
    "st.ttest_1samp(data['FSIQ'] - data['PIQ'], 0) performs the one sample t-test of the difference between the FSIQ and PIQ data, comparing the expected mean to our \"population mean\" of 0. In effect, we're testing for the null hypothesis that the difference between the data comes from a population with mean 0. (In effect, it's constructing a paired-sample t-test). In this case, we get a p-value that is 0.08, which indicates decreased support for the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### question 8)\n",
    "What are p-values and what is p-hacking? (See, for instance,  http://www.nature.com/news/scientific-method-statistical-errors-1.14700 ). What are type 1 and type 2 errors? What did Fisher, Neymann, and Egon Pearson think about p-values, type 1 and type 2 error? Who came up with what? [10 points, 200 words max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Response: p-values are the calculated probably of finding the observed data when the null hypothesis is true. We encountered the term p-hacking as we saw that data scientists can artificially manipulate the data and test parameters to uncover patterns that can be interpreted as \"statistically significant\".\n",
    "\n",
    "Type 1 errors are false positives (where we reject the null hypothesis when it is actually true)\n",
    "\n",
    "Type 2 errors are false negatives (where we fail to reject the null hypothesis when the alternative hypothesis is true)\n",
    "\n",
    "Fisher developed the theory behind the p-value as a measure used to gauge the strength of evidence against the null hypothesis. Lower p-values indicate that the null hypothesis is more unlikely. He was critical of Type I and Type II errors for not reflecting the variance in observations over the rejecting/accepting regions, and that Neymann-Pearson required constructing an laternative hypothesis that additionally required tuning (perhaps unknown) parameters.\n",
    "\n",
    "Neymann and Pearson developed the idea of formal hypothesis testing. Their idea was that regardless of the result of an experiment, we couldn't claim absolute certainty over whether one alternative was superior to another. However, they adopted a frequentist perspective and stated that one could limit the risks of concluding a difference when none exists (false positive)/or concluding no difference when one exists (false negative) by repeating experiments. They criticized p-values for violating the frequentist principle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
